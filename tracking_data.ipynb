{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' GOAL PART1: having a big unique csv file with data from all the videos \\n\\nto do that we need to: \\nOK- read the hdf5 files\\nOK- store information in the right coloumn and add missing coloums for each h5 file \\ncoloumns we want are: \\n        fly id (exp,arena,maze) -> get it from the directory with command inputpath.parent.name\\n        frame (called index) -> already there, to be extracted\\n        X and Y coordinates of head, abdomen, thorax -> already there, to be extracted\\n        time (in seconds) -> compute it (29 frames per sec)\\n        starving status  -> depends on experiment \\n        habituation status -> depends on arena number\\n    area (blu_obj, oran_obj, neutral) -> need to define thresholds either with gimpy or with the pixel thing (see notes on word) \\n\\n- join all files together \\n- save csv file \\n\\n'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' GOAL PART1: having a big unique csv file with data from all the videos \n",
    "\n",
    "to do that we need to: \n",
    "OK- read the hdf5 files\n",
    "OK- store information in the right coloumn and add missing coloums for each h5 file \n",
    "coloumns we want are: \n",
    "        fly id (exp,arena,maze) -> get it from the directory with command inputpath.parent.name\n",
    "        frame (called index) -> already there, to be extracted\n",
    "        X and Y coordinates of head, abdomen, thorax -> already there, to be extracted\n",
    "        time (in seconds) -> compute it (29 frames per sec)\n",
    "        starving status  -> depends on experiment \n",
    "        habituation status -> depends on arena number\n",
    "    area (blu_obj, oran_obj, neutral) -> need to define thresholds either with gimpy or with the pixel thing (see notes on word) \n",
    "\n",
    "- join all files together \n",
    "- save csv file \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all h5 files in the directory and subdirectories\n",
    "input = Path(\"c:/Users/win/Desktop/Alice_Samara_Videos2\") #CHANGE PATH HERE\n",
    "h5_files = list(input.rglob(\"*.h5\"))\n",
    "\n",
    "dataframes = []  # List to hold all dataframes\n",
    "\n",
    "#cycle to run the code for each video related h5 file in all the paths where it found some \n",
    "\n",
    "for testpath in h5_files:\n",
    "    #get node names and locs matrix with all info\n",
    "    with h5py.File(testpath.as_posix(), \"r\") as f:\n",
    "                dset_names = list(f.keys())\n",
    "                locs = f[\"tracks\"][:].T #this has the coordinates of the nodes (x,y)\n",
    "                node_names = [n.decode() for n in f[\"node_names\"][:]]\n",
    "            #LEGEND: locs[0] refers to the first frame\n",
    "            #locs [0][0] first frame, abdomen (1 = thorax, 2 = head)\n",
    "            #locs [0][0][0] first frame, abdomen, x value (1 = y value)\n",
    "            #locs \n",
    "    #get all locations for all the frames of a video divided by body part \n",
    "    HEAD_INDEX = 2\n",
    "    THORAX_INDEX = 1\n",
    "    ABDO_INDEX = 0\n",
    "    head_loc = locs[:, HEAD_INDEX, :, :]\n",
    "    thorax_loc = locs[:, THORAX_INDEX, :, :]\n",
    "    abdo_loc = locs[:, ABDO_INDEX, :, :]\n",
    "    \n",
    "    #build a dataframe with locations of different body parts divided by x and y (flatten to remove a parenthesis and save them in df)\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"head_x\": head_loc[:, 0].flatten(),\n",
    "            \"head_y\": head_loc[:, 1].flatten(),\n",
    "            \"thorax_x\": thorax_loc[:, 0].flatten(),\n",
    "            \"thorax_y\": thorax_loc[:, 1].flatten(),\n",
    "            \"abdo_x\": abdo_loc[:, 0].flatten(),\n",
    "            \"abdo_y\": abdo_loc[:, 1].flatten(),\n",
    "        }\n",
    "    ).reset_index()\n",
    "    #df.head() to print and see how it looks like\n",
    "\n",
    "    #now we add the missing columns to the dataframe\n",
    "\n",
    "    #time (in seconds) of each frame considering that we have 29 frames for second\n",
    "    seconds_per_frame = 1/29\n",
    "    df[\"time\"] = df[\"index\"]*seconds_per_frame    \n",
    "\n",
    "    #fly ids (exp,arena,maze)\n",
    "    #take the fly id from the directory name\n",
    "    #find the experiment/arena/maze number in the path knowing that it is always next to the word experiment/arena/maze\n",
    "    path = testpath.parent.parent.name\n",
    "    df[\"arena\"] = re.search(r'arena(\\d+)', path).group(1)\n",
    "    path = testpath.parent.name\n",
    "    df[\"maze\"] = re.search(r'maze(\\d+)', path).group(1)\n",
    "    path = testpath.parent.parent.parent.name\n",
    "    df[\"exp\"] = re.search(r'experiment(\\d+)', path).group(1)\n",
    "\n",
    "    #starving status (starved in experiment2, experiment5 fed in experiment1, experiment3, experiment4 )\n",
    "    fed_conditions = (\"mazes_experiment2_Videos\", \"mazes_experiment3_Videos\")\n",
    "    df[\"starving_cond\"] = df[\"exp\"].apply(lambda x: \"starved\" if any(cond in x for cond in fed_conditions) else \"fed\")\n",
    "\n",
    "    #habituation status (unused if arena0, arena1, arena2, blue if arena3, arena4, arena5, orange if arena6, arena7, arena8)\n",
    "    blue_arenas = (\"arena3\", \"arena4\", \"arena5\")\n",
    "    orange_arenas = (\"arena6\", \"arena7\", \"arena8\")\n",
    "    df[\"habituation_cond\"] = df[\"arena\"].apply(lambda x: \"blue\" if any(cond in x for cond in blue_arenas) else \"orange\" if any(cond in x for cond in orange_arenas) else \"unused\")\n",
    "\n",
    "    #area (blu_obj, oran_obj, neutral) -> need to define thresholds \n",
    "    # we calculate the sum of pixels in each coloumn of each frame\n",
    "\n",
    "    #first we get the video present in the folder of the experiment, arena, maze we are analyzing\n",
    "    directory = os.path.dirname(testpath)\n",
    "    trying = glob.glob(os.path.join(directory, '*.mp4'))\n",
    "\n",
    "    #Get the first frame of the video\n",
    "    cap = cv2.VideoCapture(trying[0])\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "\n",
    "    # Convert the image to grayscale if it's not already\n",
    "    if len(frame.shape) == 3:  # Check if the image has color channels\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate the sum of pixel values for each column (x-coordinate)\n",
    "    column_pixel_sums = np.sum(frame, axis=0)\n",
    "\n",
    "    # Create an array of x-coordinates\n",
    "    x_values = np.arange(len(column_pixel_sums))\n",
    "\n",
    "    '''# Create a new figure\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot the pixel sums\n",
    "    ax.plot(x_values, column_pixel_sums)\n",
    "\n",
    "    # Add a grid\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Set the x-ticks with an interval of 5\n",
    "    ax.set_xticks(np.arange(min(x_values), max(x_values)+1, 5))\n",
    "\n",
    "    # Rotate x-axis labels\n",
    "    plt.xticks(rotation=90)\n",
    "\n",
    "    # Set the labels and title\n",
    "    ax.set_xlabel('Column index')\n",
    "    ax.set_ylabel('Sum of pixel values')\n",
    "    ax.set_title('Sum of pixel values for each column')'''\n",
    "\n",
    "    # Find peaks with a minimum distance of 55\n",
    "    column_pixel_sums_1d = column_pixel_sums.flatten()\n",
    "    peaks, properties = scipy.signal.find_peaks(column_pixel_sums_1d, height = (30_000, 70_000), distance=55)\n",
    "\n",
    "    #it returns the indices of peaks in column_pixel_sums_1d that satisfy all given conditions\n",
    "    #properties is a dictionary containing properties of the peaks and we are interested in the height of them\n",
    "\n",
    "    # Get the heights of the peaks\n",
    "    peak_heights = properties['peak_heights']\n",
    "\n",
    "    # Sort the peaks by their heights in descending order and get the indices of the two highest peaks\n",
    "    highest_peaks_indices = np.argsort(peak_heights)[-2:]\n",
    "\n",
    "    # Get the x values of the two highest peaks\n",
    "    highest_peaks_x_values = peaks[highest_peaks_indices]\n",
    "\n",
    "    '''#plot red dots on the 2 highest peaks on the graph\n",
    "    ax.plot(highest_peaks_x_values, column_pixel_sums[highest_peaks_x_values], 'ro')\n",
    "    # Show the plot\n",
    "    plt.show()'''\n",
    "\n",
    "    #extract the first and second highest peak values\n",
    "    left_peak = highest_peaks_x_values[0]\n",
    "    right_peak = highest_peaks_x_values[1]\n",
    "\n",
    "    #let's add a column with the position of the blue object relative to the fly prospective\n",
    "    df[\"pos_blue_obj\"] = \"left\"\n",
    "    # Add \"area\" column to DataFrame\n",
    "\n",
    "    #if we are analysign the maze 1 right and left are opposite (because it was rotated during the cropping)\n",
    "    if df[\"maze\"].iloc[0] == \"1\":\n",
    "        left_peak, right_peak = right_peak, left_peak\n",
    "        df[\"pos_blue_obj\"] = \"right\"\n",
    "        \n",
    "    # if the thorax of the fly is lower than the left peak, the fly is in the left area (corresponding to the blue object)\n",
    "    #if it is higher than the right peak, the fly is in the right area (right obj), otherwise it is in the neutral area\n",
    "    #the y coordinate of the thorax also have to be over the middle line to be sure the fly is not in the resting area (which is larger). Max y value is around 480 so we consider 240 as the middle line\n",
    "\n",
    "    df[\"area\"] = \"neutral\"\n",
    "    \n",
    "    #if thorax_x is lower than left peak and thorax_y < 240, the fly is in the left area (y axes goes from top to bottom so lower values are higher on the screen)\n",
    "    df.loc[(df[\"thorax_x\"] < left_peak) & (df[\"thorax_y\"] < 240), \"area\"] = \"blue\"\n",
    "    df.loc[(df[\"thorax_x\"] > right_peak) & (df[\"thorax_y\"] < 240), \"area\"] = \"orange\"\n",
    "\n",
    "    #save the dataframe in the list of dataframes\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all dataframes\n",
    "combined_df = pd.concat(dataframes)\n",
    "\n",
    "# Save the concatenated dataframe to a CSV file and specify the path\n",
    "#if the file already exhists remove it\n",
    "if os.path.exists(input / 'fly_data_AliceSamara.csv'):\n",
    "    os.remove(input / 'fly_data_AliceSamara.csv')\n",
    "combined_df.to_csv(input / 'fly_data_AliceSamara.csv', index=False)\n",
    "\n",
    "#to see the single dataframe\n",
    "#df \n",
    "#to see the concatenated dataframe\n",
    "#combined_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "img_analysis_ramdya",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
