{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal\n",
    "import os\n",
    "import glob \n",
    "from scipy.ndimage import uniform_filter1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' GOAL PART1: having a big unique csv file with data from all the videos \\n\\nto do that we need to: \\nOK- read the hdf5 files\\nOK- store information in the right coloumn and add missing coloums for each h5 file \\ncoloumns we want are: \\n        fly id (exp,arena,maze) -> get it from the directory with command inputpath.parent.name\\n        frame (called index) -> already there, to be extracted\\n        X and Y coordinates of head, abdomen, thorax -> already there, to be extracted\\n        time (in seconds) -> compute it (29 frames per sec)\\n        starving status  -> depends on experiment \\n        habituation status -> depends on arena number\\n    area (blu_obj, oran_obj, neutral) -> need to define thresholds either with gimpy or with the pixel thing (see notes on word) \\n\\n- join all files together \\n- save csv file \\n\\n'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' GOAL PART1: having a big unique csv file with data from all the videos \n",
    "\n",
    "to do that we need to: \n",
    "OK- read the hdf5 files\n",
    "OK- store information in the right coloumn and add missing coloums for each h5 file \n",
    "coloumns we want are: \n",
    "        fly id (exp,arena,maze) -> get it from the directory with command inputpath.parent.name\n",
    "        frame (called index) -> already there, to be extracted\n",
    "        X and Y coordinates of head, abdomen, thorax -> already there, to be extracted\n",
    "        time (in seconds) -> compute it (29 frames per sec)\n",
    "        starving status  -> depends on experiment \n",
    "        habituation status -> depends on arena number\n",
    "    area (blu_obj, oran_obj, neutral) -> need to define thresholds either with gimpy or with the pixel thing (see notes on word) \n",
    "\n",
    "- join all files together \n",
    "- save csv file \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all h5 files in the directory and subdirectories\n",
    "input = Path(\"/home/matthias/Videos/Alice_Samara_Videos2\") #CHANGE PATH HERE\n",
    "h5_files = list(input.rglob(\"*.h5\"))\n",
    "\n",
    "dataframes = []  # List to hold all dataframes\n",
    "\n",
    "#cycle to run the code for each video related h5 file in all the paths where it found some \n",
    "\n",
    "for testpath in h5_files:\n",
    "    #get node names and locs matrix with all info\n",
    "    with h5py.File(testpath.as_posix(), \"r\") as f:\n",
    "                dset_names = list(f.keys())\n",
    "                locs = f[\"tracks\"][:].T #this has the coordinates of the nodes (x,y)\n",
    "                node_names = [n.decode() for n in f[\"node_names\"][:]]\n",
    "            #LEGEND: locs[0] refers to the first frame\n",
    "            #locs [0][0] first frame, abdomen (1 = thorax, 2 = head)\n",
    "            #locs [0][0][0] first frame, abdomen, x value (1 = y value)\n",
    "            #locs \n",
    "    #get all locations for all the frames of a video divided by body part \n",
    "    HEAD_INDEX = 2\n",
    "    THORAX_INDEX = 1\n",
    "    ABDO_INDEX = 0\n",
    "    head_loc = locs[:, HEAD_INDEX, :, :]\n",
    "    thorax_loc = locs[:, THORAX_INDEX, :, :]\n",
    "    abdo_loc = locs[:, ABDO_INDEX, :, :]\n",
    "    \n",
    "    #build a dataframe with locations of different body parts divided by x and y (flatten to remove a parenthesis and save them in df)\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"head_x\": head_loc[:, 0].flatten(),\n",
    "            \"head_y\": head_loc[:, 1].flatten(),\n",
    "            \"thorax_x\": thorax_loc[:, 0].flatten(),\n",
    "            \"thorax_y\": thorax_loc[:, 1].flatten(),\n",
    "            \"abdo_x\": abdo_loc[:, 0].flatten(),\n",
    "            \"abdo_y\": abdo_loc[:, 1].flatten(),\n",
    "        }\n",
    "    ).reset_index()\n",
    "    #df.head() to print and see how it looks like\n",
    "\n",
    "    #now we add the missing columns to the dataframe\n",
    "\n",
    "    #time (in seconds) of each frame considering that we have 29 frames for second\n",
    "    seconds_per_frame = 1/29\n",
    "    df[\"time\"] = df[\"index\"]*seconds_per_frame    \n",
    "\n",
    "    #fly ids (exp,arena,maze)\n",
    "    #take the fly id from the directory name\n",
    "    #find the experiment/arena/maze number in the path knowing that it is always next to the word experiment/arena/maze\n",
    "    path = testpath.parent.parent.name\n",
    "    df[\"arena\"] = re.search(r'arena(\\d+)', path).group(1)\n",
    "    path = testpath.parent.name\n",
    "    df[\"maze\"] = re.search(r'maze(\\d+)', path).group(1)\n",
    "    path = testpath.parent.parent.parent.name\n",
    "    df[\"exp\"] = re.search(r'experiment(\\d+)', path).group(1)\n",
    "\n",
    "    #starving status (starved in experiment2, experiment5 fed in experiment1, experiment3, experiment4 )\n",
    "    fed_conditions = (\"mazes_experiment2_Videos\", \"mazes_experiment3_Videos\")\n",
    "    df[\"starving_cond\"] = df[\"exp\"].apply(lambda x: \"starved\" if any(cond in x for cond in fed_conditions) else \"fed\")\n",
    "\n",
    "    #habituation status (unused if arena0, arena1, arena2, blue if arena3, arena4, arena5, orange if arena6, arena7, arena8)\n",
    "    blue_arenas = (\"arena3\", \"arena4\", \"arena5\")\n",
    "    orange_arenas = (\"arena6\", \"arena7\", \"arena8\")\n",
    "    df[\"habituation_cond\"] = df[\"arena\"].apply(lambda x: \"blue\" if any(cond in x for cond in blue_arenas) else \"orange\" if any(cond in x for cond in orange_arenas) else \"unused\")\n",
    "\n",
    "    #area (blu_obj, oran_obj, neutral) -> need to define thresholds \n",
    "    # we calculate the sum of pixels in each coloumn of each frame\n",
    "\n",
    "    #first we get the video present in the folder of the experiment, arena, maze we are analyzing\n",
    "    directory = os.path.dirname(testpath)\n",
    "    trying = glob.glob(os.path.join(directory, '*.mp4'))\n",
    "\n",
    "    #Get the first frame of the video\n",
    "    cap = cv2.VideoCapture(trying[0])\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "\n",
    "    # Convert the image to grayscale if it's not already\n",
    "    if len(frame.shape) == 3:  # Check if the image has color channels\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    #normalize the pixel values of the image\n",
    "    def normalize_image(image):\n",
    "        norm_image = cv2.normalize(image, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "        return norm_image\n",
    "    frame = normalize_image(frame)\n",
    "\n",
    "    # Calculate the sum of pixel values for each column (x-coordinate)\n",
    "    column_pixel_sums = np.sum(frame, axis=0)\n",
    "\n",
    "    # Create an array of x-coordinates\n",
    "    x_values = np.arange(len(column_pixel_sums))\n",
    "\n",
    "#to plot the sum of pixel values for each column\n",
    "    '''# Create a new figure\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot the pixel sums\n",
    "    ax.plot(x_values, column_pixel_sums)\n",
    "\n",
    "    # Add a grid\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Set the x-ticks with an interval of 5\n",
    "    ax.set_xticks(np.arange(min(x_values), max(x_values)+1, 5))\n",
    "\n",
    "    # Rotate x-axis labels\n",
    "    plt.xticks(rotation=90)\n",
    "\n",
    "    # Set the labels and title\n",
    "    ax.set_xlabel('Column index')\n",
    "    ax.set_ylabel('Sum of pixel values')\n",
    "    ax.set_title('Sum of pixel values for each column')'''\n",
    "\n",
    "    # Find x coordinates of the plateau \n",
    "    column_pixel_sums_1d = column_pixel_sums.flatten()\n",
    "\n",
    "    # Apply a smoothing function to reduce noise\n",
    "    smoothed_sums = uniform_filter1d(column_pixel_sums_1d, size=4)\n",
    "\n",
    "    # Threshold for detecting the plateau (on the y = 3000, distance along x of the plateau = at least 40 )\n",
    "    threshold = 80000\n",
    "    min_plateau_length = 40\n",
    "\n",
    "    # Find indices where the smoothed sums exceed the threshold\n",
    "    above_threshold = smoothed_sums > threshold\n",
    "\n",
    "    # Identify the start and end points of the plateau\n",
    "    plateau_start = None\n",
    "    plateau_end = None\n",
    "\n",
    "    for i in range(1, len(above_threshold)):\n",
    "        if above_threshold[i] and not above_threshold[i-1]:\n",
    "            start = i\n",
    "        if not above_threshold[i] and above_threshold[i-1]:\n",
    "            end = i\n",
    "            if end - start >= min_plateau_length:\n",
    "                plateau_start = start\n",
    "                plateau_end = end\n",
    "                break\n",
    "\n",
    "    # Mark the boundary points on the plot and show it\n",
    "    '''plt.figure(figsize=(10, 6))\n",
    "    plt.plot(smoothed_sums)\n",
    "    if plateau_start is not None and plateau_end is not None:\n",
    "        plt.axvline(x=plateau_start, color='r', linestyle='--', label=f'Start at {plateau_start}')\n",
    "        plt.axvline(x=plateau_end, color='r', linestyle='--', label=f'End at {plateau_end}')\n",
    "    ## Set the x-ticks with an interval of 5 and rotate label of 90 degrees\n",
    "    plt.xticks(np.arange(min(x_values), max(x_values)+1, 5), rotation=90)\n",
    "    #\n",
    "    plt.xlabel('Column index')\n",
    "    plt.ylabel('Sum of pixel values')\n",
    "    plt.title('Sum of pixel values for each column with boundaries')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()'''\n",
    "\n",
    "    left_peak = plateau_start\n",
    "    right_peak = plateau_end\n",
    "\n",
    "\n",
    "    #let's add a column with the position of the blue object relative to the fly prospective\n",
    "    df[\"pos_blue_obj\"] = \"left\"\n",
    "    # Add \"area\" column to DataFrame\n",
    "\n",
    "    #if we are analysign the maze 1 right and left are opposite (because it was rotated during the cropping)\n",
    "    if df[\"maze\"].iloc[0] == \"1\":\n",
    "        left_peak, right_peak = right_peak, left_peak\n",
    "        df[\"pos_blue_obj\"] = \"right\"\n",
    "        \n",
    "    # if the thorax of the fly is lower than the left peak, the fly is in the left area (corresponding to the blue object)\n",
    "    #if it is higher than the right peak, the fly is in the right area (right obj), otherwise it is in the neutral area\n",
    "    #the y coordinate of the thorax also have to be over the middle line to be sure the fly is not in the resting area (which is larger). Max y value is around 480 so we consider 240 as the middle line\n",
    "\n",
    "    df[\"area\"] = \"neutral\"\n",
    "    \n",
    "    #if thorax_x is lower than left peak and thorax_y < 240, the fly is in the left area (y axes goes from top to bottom so lower values are higher on the screen)\n",
    "    df.loc[(df[\"thorax_x\"] < left_peak) & (df[\"thorax_y\"] < 240), \"area\"] = \"blue\"\n",
    "    df.loc[(df[\"thorax_x\"] > right_peak) & (df[\"thorax_y\"] < 240), \"area\"] = \"orange\"\n",
    "\n",
    "    #save the dataframe in the list of dataframes\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all dataframes\n",
    "combined_df = pd.concat(dataframes)\n",
    "\n",
    "# Save the concatenated dataframe to a CSV file and specify the path\n",
    "#if the file already exhists remove it\n",
    "if os.path.exists(input / 'fly_data_AliceSamara.csv'):\n",
    "    os.remove(input / 'fly_data_AliceSamara.csv')\n",
    "    \n",
    "#consider the commas as column separators for the csv file\n",
    "\n",
    "\n",
    "combined_df.to_csv(input / 'fly_data_AliceSamara.csv', index=False)\n",
    "\n",
    "#to see the single dataframe\n",
    "#df \n",
    "#to see the concatenated dataframe\n",
    "#combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>head_x</th>\n",
       "      <th>head_y</th>\n",
       "      <th>thorax_x</th>\n",
       "      <th>thorax_y</th>\n",
       "      <th>abdo_x</th>\n",
       "      <th>abdo_y</th>\n",
       "      <th>time</th>\n",
       "      <th>arena</th>\n",
       "      <th>maze</th>\n",
       "      <th>exp</th>\n",
       "      <th>starving_cond</th>\n",
       "      <th>habituation_cond</th>\n",
       "      <th>pos_blue_obj</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>134.416687</td>\n",
       "      <td>443.169678</td>\n",
       "      <td>150.718246</td>\n",
       "      <td>443.773621</td>\n",
       "      <td>172.266769</td>\n",
       "      <td>446.496918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>fed</td>\n",
       "      <td>unused</td>\n",
       "      <td>left</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>134.481506</td>\n",
       "      <td>443.224609</td>\n",
       "      <td>153.064728</td>\n",
       "      <td>443.615417</td>\n",
       "      <td>172.361008</td>\n",
       "      <td>446.615692</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>fed</td>\n",
       "      <td>unused</td>\n",
       "      <td>left</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>134.433365</td>\n",
       "      <td>443.181183</td>\n",
       "      <td>150.749207</td>\n",
       "      <td>443.730011</td>\n",
       "      <td>172.447113</td>\n",
       "      <td>446.680237</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>fed</td>\n",
       "      <td>unused</td>\n",
       "      <td>left</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>134.386978</td>\n",
       "      <td>443.216705</td>\n",
       "      <td>150.719879</td>\n",
       "      <td>443.798920</td>\n",
       "      <td>172.404236</td>\n",
       "      <td>446.566772</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>fed</td>\n",
       "      <td>unused</td>\n",
       "      <td>left</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>134.329590</td>\n",
       "      <td>440.829559</td>\n",
       "      <td>150.600082</td>\n",
       "      <td>443.740784</td>\n",
       "      <td>172.276642</td>\n",
       "      <td>446.632080</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>fed</td>\n",
       "      <td>unused</td>\n",
       "      <td>left</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      head_x      head_y    thorax_x    thorax_y      abdo_x  \\\n",
       "0      0  134.416687  443.169678  150.718246  443.773621  172.266769   \n",
       "1      1  134.481506  443.224609  153.064728  443.615417  172.361008   \n",
       "2      2  134.433365  443.181183  150.749207  443.730011  172.447113   \n",
       "3      3  134.386978  443.216705  150.719879  443.798920  172.404236   \n",
       "4      4  134.329590  440.829559  150.600082  443.740784  172.276642   \n",
       "\n",
       "       abdo_y      time arena maze exp starving_cond habituation_cond  \\\n",
       "0  446.496918  0.000000     2    0   5           fed           unused   \n",
       "1  446.615692  0.034483     2    0   5           fed           unused   \n",
       "2  446.680237  0.068966     2    0   5           fed           unused   \n",
       "3  446.566772  0.103448     2    0   5           fed           unused   \n",
       "4  446.632080  0.137931     2    0   5           fed           unused   \n",
       "\n",
       "  pos_blue_obj     area  \n",
       "0         left  neutral  \n",
       "1         left  neutral  \n",
       "2         left  neutral  \n",
       "3         left  neutral  \n",
       "4         left  neutral  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique combinations of experiment, arena, and maze: 135\n"
     ]
    }
   ],
   "source": [
    "# Get the number of unique values of combinations of experiment, arena, and maze\n",
    "\n",
    "unique_combinations = combined_df[[\"exp\", \"arena\", \"maze\"]].drop_duplicates()\n",
    "\n",
    "print(f\"Number of unique combinations of experiment, arena, and maze: {len(unique_combinations)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "img_analysis_ramdya",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
